{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "* 試著想想看, 非監督學習是否有可能使用評價函數 (Metric) 來鑑別好壞呢?  \n",
    "(Hint : 可以分為 \"有目標值\" 與 \"無目標值\" 兩個方向思考)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "無監督學習主要是為了挖掘數據中的locality局部關係或局部與全局的關係，評估方法主要有\n",
    "* **密度或距離**\n",
    "\n",
    "* **統計學手段**\n",
    "\n",
    "* **監督學習方法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **將無監督學習變成有監督學習 - 生成標籤**\n",
    "\n",
    "        e.g.使用順序集成(Sequential Ensemble)的方法進行異常檢測，在每次的迭代，通過分析多個基學習器的相關系，生成偽標籤來淘汰表現不佳的基學習器。通過集成的方法生成了可信度較高的標籤，從而轉換為一種監督手段。\n",
    "\n",
    "2. **相似度分析(Similarity Analysis)**\n",
    "\n",
    "        (簡單說明): 從聚類的角度來看，我們希望同一個簇的數據盡量相似，而不同簇之間的差別越大越好。\n",
    "\n",
    "        * **簇內相似性：越相似越好** ---> 高簇內相似性\n",
    "        * **簇間差異性：越不同越好** ---> 高簇間差異性\n",
    "\n",
    "\n",
    "3. **分布擬合、排序、統計學方法**\n",
    "\n",
    "\n",
    "        * 可以嘗試直接對分布進行擬合。(參考: S. Rayana and L. Akoglu. Less is More: Building Selective Anomaly Ensembles\n",
    "\n",
    "        * 信息論和統計學方法 ---> 測量相似性，或者作為**\"距離度量\"**。\n",
    "            e.g. Mutual Information, Normalized Mutual Information\n",
    "            (p.s. Mutual Information 只適合用於衡量**離散**隨機變量，如要做**連續**隨機變量，可使用 Maximal Information Coefficient.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**无监督学习中的Bias-Variance Decomposition**\n",
    "\n",
    "\n",
    "    监督学习中的Bias-Variance分解已经是比较成熟的模型了，知乎上也有很多讨论[1]。而模型泛化能力(generalization)通过分解均方误差，Mean Squared Error(MSE)，的期望(Expectation)量化的：\n",
    "\n",
    "\\begin{split} E (Y-\\hat{Y})^2 & = E[f(X) + \\epsilon- \\hat{f}(X)]^2 \\qquad \\qquad \\\\ & = [f(X)-\\hat{f}(X)]^2+Var(\\epsilon )\\\\ &= Bias^2 + Variance + Variance(\\epsilon) \\end{split}\n",
    "\n",
    "    因此，理想模型下一个模型的泛化误差有偏差(bias)的平方，方差(variance)，和无法消除的噪音/错误(intrinsic noise)共同决定。而得到这个理想公式的前提就是你知道使用MSE来对误差进行分析。在无监督学习中，输出的结果往往有不同的含义，比如聚类的输出结果可能是簇(cluster)的编号，而异常检测的结果可能是一个点是否是异常，那么如何再量化？\n",
    "\n",
    "    虽然这方面的研究比较有限，但如果退一步我们依然可以套用类似的框架。以聚类为例，如果假设我们有2个簇，然后要求我们的输出值是一个[0,1]之间的数，越小越代表其倾向于是簇0，反之则是簇1。异常检测的话，可以假设存在函数g(x)输出异常评分，同时假设存在真实的x异常评分再套用上面的框架。即使无监督学习没有事实真相(ground truth)，但我们依然可以在MSE的框架下构建一个Bias-Variance分解，来帮助我们理解如何提升模型。花了篇幅讨论主要是想说明，虽然无监督学习没有标签，但从基本理论上依然可以借鉴很多监督学习的思路，也包括评估方法。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.zhihu.com/question/30855292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
